{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from global_variables import *\n",
    "from load_files import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.comment_text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(list(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded = sequence.pad_sequences(tokenized, MAX_TEXT_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIMS   = 100\n",
    "embedding_matrix = np.zeros((MAX_FEATURES, EMBEDDING_DIMS))\n",
    "glove100         = open(GLOVE100, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in glove100:\n",
    "    \n",
    "    values = line.split()\n",
    "    word   = values[0]\n",
    "    coefs  = np.asarray(values[1:], dtype='float32')\n",
    "    \n",
    "    EMBEDDINGS_W2V[word] = coefs\n",
    "\n",
    "glove100.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, index in tokenizer.word_index.items():\n",
    "    \n",
    "    if index > MAX_FEATURES - 1:\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        embedding_vector = EMBEDDINGS_W2V.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(\n",
    "    MAX_FEATURES,\n",
    "    EMBEDDING_DIMS,\n",
    "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False))\n",
    "\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv1D(\n",
    "    FILTERS_COUNT,\n",
    "    FILTER_SIZE,\n",
    "    padding='valid',\n",
    "    activation='relu'))\n",
    "\n",
    "model.add(MaxPooling1D())\n",
    "\n",
    "model.add(Conv1D(\n",
    "    FILTERS_COUNT,\n",
    "    5,\n",
    "    padding='valid',\n",
    "    activation='relu'))\n",
    "\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(\n",
    "    HIDDEN_DIMS,\n",
    "    activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(\n",
    "    1,\n",
    "    activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         2000000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 250)         75250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 250)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 250)         312750    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 2,451,001\n",
      "Trainable params: 451,001\n",
      "Non-trainable params: 2,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss      = 'binary_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics   = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_padded, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135635 samples, validate on 23936 samples\n",
      "Epoch 1/3\n",
      "135635/135635 [==============================] - 58s 425us/sample - loss: 0.1445 - acc: 0.9473 - val_loss: 0.1175 - val_acc: 0.9566- los - ETA: 53s - loss: 0.1835 - acc:  - ETA: 52s - loss: 0.1829 - acc - ETA: 47s - loss: 0.1743 - acc:  - ETA: 46 - ETA: 45s - loss: 0.1723 - acc: 0.93 - ETA: 44s - loss: 0.1719 - a - ETA: 44s - loss: 0.1713 - - ETA: 43s - loss: 0.1708 - acc - ETA: 43s - loss: 0. - ETA: 42s - lo - ETA: 41s - loss: 0.1692 - acc: 0. - ETA - ETA: 39s - loss: 0.1664 - acc:  - ETA: 39s - loss: 0.1662 - acc: 0. - ETA: 39s - loss: 0.1658 - acc: 0. - ETA: 38s - loss: 0.16 - ETA: 38s - loss: 0.1648 - acc: 0.94 - ETA: 38s - lo - ETA: 37s - loss: 0.1638 - acc:  - ETA: 36s - loss: 0.1634 - - ETA: 36s - loss: 0.1633 - acc: 0. - ETA: 36s - loss: 0.1630 - a - ETA: 35s - loss: 0.1627 - E - ETA: 32s - loss - ETA:  - ETA: 21s - loss: 0.1535 - acc: 0.94 - ETA: 21s - loss: 0.1535 - - ETA: 21s - loss: 0.1535 - acc: 0. - ETA: 21s - loss: 0.1533 - acc:  - ETA: 20s - lo - ETA: 19s - loss: 0.1528 - acc:  - ETA: 19s - loss - ETA: 18s - loss: 0.1521 - acc: 0.94 - ETA: 18s - loss: 0.1520 - acc: 0.94 - ETA: 18s - loss: 0.1519 - acc - ETA: 18s - loss: 0.1520 - ETA: 18s - loss: 0.1516 - acc: 0. - ETA: 17s - loss: 0.1517 - acc: 0. - ETA: 17s - lo - ETA: 15s - loss:  - ETA: 13s - loss: 0.1502 - - ETA: 13s - loss: 0.1502 - - ETA: 12s - loss: 0.1498 - acc: 0. - ETA: 12s - loss: 0.1497 - acc: 0.94 - ETA: 12s - loss: 0.14 - ETA: 10s - loss: 0.1488 - acc - ETA: 10s - ETA: 9s - loss: 0 - ETA: 8s - loss: 0.1 - ETA: 7s - loss: 0.1471  - ETA: 6s - loss: 0.1467 -  - ETA: 5s - loss: 0.1462 - ac - ETA: 4s - loss: 0.1461 - acc: 0.94 - ETA: 4s - loss: 0.1462 - acc: 0. - ETA: 4s - loss: - ETA: 3s - loss: 0.1455 - acc: 0 -  - ETA: 0s - loss: 0.1447 - acc: 0.94 - ETA: 0s - loss: 0.1446 - acc: \n",
      "Epoch 2/3\n",
      "135635/135635 [==============================] - 55s 407us/sample - loss: 0.1170 - acc: 0.9570 - val_loss: 0.1115 - val_acc: 0.9591ETA: 49s - loss: 0.1188 - a - ETA: 49s - loss: 0.1195 - acc:  - ETA:  - ETA: 48s - loss: 0. - ETA: 47s - loss: 0.1171 - ETA: 47s - loss: 0.11 - ETA: 46s  - ETA - ETA: 44s -  - ETA: 40s - loss: 0.1187 - acc - ETA: 40s - loss: 0.1186 - acc:  - ETA:  - ETA: 39s -  - ETA: 38s  - ETA: 36s - loss - ETA: 35s - loss: 0.11 - ETA: 34s - loss - ETA - ETA:  - ETA: 28s - loss: 0.1186 - acc:  - ETA: 28s - loss - ETA: 27s - loss: 0.1182 - ETA: 24s  - ETA: 23s - loss: 0.1182 - acc - ETA: 22s - loss: 0. - ETA: 21s - loss: 0.1177 - acc: 0.95 - ETA: 21s - loss:  - ETA - ETA: 19s - loss: 0.1174 - acc: 0.95 - ETA: 19s - loss: 0.1175 - acc: 0.95 - ETA: 19s - loss:  - ETA: 19s - loss: 0.1171 - acc:  - ETA: 18s - loss: 0.1172 - acc - ETA: 18s - loss: 0.1171 - acc: 0. - ETA: 18s - loss: 0.1171 - acc: 0.95 - ETA: 18s - loss - ETA: 17s - loss: 0.1170 - acc: 0.95 - ETA: 17s - loss: 0.1170 - acc: 0.95 - ETA: 17s -  - ETA: 16s - lo - ETA: 16s - loss: 0.1171 - acc: 0.95 - ETA: 16s - loss: 0.1172 - - ETA: 15s - loss: 0.1173 - - ETA: 15s - loss: 0.1175 - - ETA: 14s - loss: 0.1175 - acc: 0.95 - ETA: 14s - loss:  - ETA: 14 - ETA: 10s - loss: 0.1173 - - ETA: 10s - lo - ETA: 9s - loss: 0.1175 - acc - ETA: 8s - loss: 0.1174 - acc: 0.95 - ETA: 8s - loss: 0 - ET - ETA: 5s - loss: 0 - ETA: 4s - lo - ETA: 0s - loss: 0.1170 - acc: 0.957 - ETA: 0s - loss: 0.1170 - acc: 0.95\n",
      "Epoch 3/3\n",
      "135635/135635 [==============================] - 55s 408us/sample - loss: 0.1067 - acc: 0.9602 - val_loss: 0.1127 - val_acc: 0.9585- ETA: 45s -  - ETA: 43s - loss: 0.1082 - acc:  - ETA: 42s - loss: 0.1080 - acc:  - ETA: 41s - loss: 0.1089 - acc: 0. - ETA: 41s - loss - ETA: 40s - loss: 0.1084 - acc:  - ETA: 40s - loss - ETA: 39s - loss:  - ETA: 38s - loss: 0.1089 - acc:  - ETA: 38s  - ETA: 37s -  - ETA: 36s - loss - ETA: 36s - loss: 0.1075 - acc: 0. - ETA: 36 - ETA: 35s - loss: 0.10 - ETA: 34s - loss: 0.1080 - acc: 0. - ETA: 34s - loss: 0.1080 - acc: 0.95 - ETA: 34s - loss: 0.1079 - acc - E - ETA: 33s - loss: 0.1074 - acc - ETA - ETA: 31s - loss: 0.1079 - acc: 0. - ETA: 31s - loss: 0. - ETA: 31s - loss: 0.1075 - - ETA: 29s - loss: 0.1068 - - ETA: 29s - loss: 0.1067 - acc:  - ETA: 28s - loss: 0.1067 - ETA: 26s - loss: 0.1056 - acc - ETA: 25s - loss: 0.1057 - acc: 0.96 - E - ETA: 24s - loss: 0.1059 - acc: 0.96 - ETA: 24s - loss: 0.1059 - acc: 0.96 - ETA: 24s - loss: 0.1059 - ETA: 24 - ETA: 21s -  - ETA: 19 - ETA: 15s - loss:  - ETA: 14s - loss: 0.1077 - acc - - ETA: 13s - loss - ETA: 12s - loss: 0.1069 - acc: 0. - ETA: 12s - loss: 0.1070 - ETA: 11s - loss:  - - ETA: 10s - loss: 0.107 - ETA: 9 - ETA: 7s - loss: 0.1070 - acc: - ETA: 6s - loss: 0.1068 - acc - ETA: 6s - loss: 0.1067 - acc: 0 - ETA: 6s - loss: 0.1067 - acc: 0.960 - ETA: 5s - loss: 0.1066 - acc: 0.9 - ETA: 5s - loss: 0.1066 - acc: 0 - ETA: 5s - loss: 0.1066 - acc: 0.9 - ETA: 5s - loss: 0.1065 - acc: 0.96 - ETA: 5s - loss: 0.1066 - ac - ETA: 4s - loss: 0.1065 - acc:  - ETA: 4s - loss: 0.1 - ETA: 3s - loss: 0.1067 - acc: 0.96 - ETA: 3s - loss: 0.1067 - acc: 0. - ETA: 2s - loss: 0.1068 - acc - ETA: 2s - loss: 0.1068 - a - ETA: 1s - loss: 0.1066 - acc: 0.960 - ETA: 1s - loss: 0.1067 - acc - ETA: 1s - loss: 0.1066 -  - ETA: 0s - loss: 0.1068 - acc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19074e08188>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23936/23936 [==============================] - 3s 121us/sample - loss: 0.1127 - acc: 0.9585\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_valid, y_valid, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss    : 0.11273200857766809\n",
      "Accuracy: 0.9585144\n"
     ]
    }
   ],
   "source": [
    "print('Loss    :', loss)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.comment_text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = sequence.pad_sequences(tokenized, MAX_TEXT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 19s 124us/sample\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(\n",
    "    X_test_padded,\n",
    "    verbose=1,\n",
    "    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for pred in y_pred:\n",
    "    if pred < 0.5:\n",
    "        predictions.append('Non_toxic')\n",
    "    else:\n",
    "        predictions.append('Toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['toxic'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>Please do not add nonsense to Wikipedia. Such ...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>\" \\n Only a fool can believe in such numbers. ...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>== Double Redirects == \\n\\n When fixing double...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0002eadc3b301559</td>\n",
       "      <td>I think its crap that the link to roggenbier i...</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>\"::: Somebody will invariably try to add Relig...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0003806b11932181</td>\n",
       "      <td>, 25 February 2010 (UTC) \\n\\n :::Looking it ov...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>\" \\n\\n It says it right there that it IS a typ...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>\" \\n\\n == Before adding a new product to the l...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000634272d0d44eb</td>\n",
       "      <td>==Current Position== \\n Anyone have confirmati...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000663aff0fffc80</td>\n",
       "      <td>this other one from 1897</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000689dd34e20979</td>\n",
       "      <td>== Reason for banning throwing == \\n\\n This ar...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000834769115370c</td>\n",
       "      <td>:: Wallamoose was changing the cited material ...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000844b52dee5f3f</td>\n",
       "      <td>|blocked]] from editing Wikipedia.   |</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00084da5d4ead7aa</td>\n",
       "      <td>==Indefinitely blocked== \\n I have indefinitel...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00091c35fa9d0465</td>\n",
       "      <td>== Arabs are committing genocide in Iraq, but ...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000968ce11f5ee34</td>\n",
       "      <td>Please stop. If you continue to vandalize Wiki...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0009734200a85047</td>\n",
       "      <td>== Energy  == \\n\\n I have edited the introduct...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00097b6214686db5</td>\n",
       "      <td>:yeah, thanks for reviving the tradition of pi...</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0009aef4bd9e1697</td>\n",
       "      <td>MLM Software,NBFC software,Non Banking Financi...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>000a02d807ae0254</td>\n",
       "      <td>@RedSlash, cut it short. If you have sources s...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000a6c6d4e89b9bc</td>\n",
       "      <td>==================== \\n Deception is the way o...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000bafe2080bba82</td>\n",
       "      <td>. \\n\\n           Jews are not a race because y...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000bf0a9894b2807</td>\n",
       "      <td>:::If Ollie or others think that one list of t...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>000c50dceb1eed2b</td>\n",
       "      <td>\" \\n *Support Per Jimbo and WP:google \"\"Climat...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>000c9b92318552d1</td>\n",
       "      <td>Professors to the Manhatten Project.</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>000ce41d86f2b886</td>\n",
       "      <td>:::::I have added more wikilinks to my section...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>000cf60dbaed8c02</td>\n",
       "      <td>\" \\n\\n :Not sure whether this is notable enoug...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>000d4f120d5a7303</td>\n",
       "      <td>일이삼사오육칠팔구하고십이요 에헤헤 으헤 으헤 으허허</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>000d60becb7d1a67</td>\n",
       "      <td>I've deleted the page , as we have no evidence...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>000fc381d4895598</td>\n",
       "      <td>== Nation Radio - request for comment == \\n\\n ...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>000ff37cf57ab537</td>\n",
       "      <td>\"\"\" (per your user page)\"</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>001068b809feee6b</td>\n",
       "      <td>\" \\n\\n ==balance== \\n This page has one senten...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0011c58fcfd6bf91</td>\n",
       "      <td>\" \\n\\n *@EdJohnston. Your question was about f...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0011cefc680993ba</td>\n",
       "      <td>REDIRECT Talk:Mi Vida Eres Tú</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0011ef6aa33d42e6</td>\n",
       "      <td>\" \\n I'm not convinced that he was blind. Wher...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0012706ac77a7b37</td>\n",
       "      <td>== Thanks for the Barnstar! == \\n\\n Thank you ...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0012bb72f20ae971</td>\n",
       "      <td>\" \\n\\n == Ref: SS Ponzi Scheme == \\n\\n Hi Padi...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0012bbcbd6958302</td>\n",
       "      <td>\" \\n\\n Look, Gerry Spence has NOT \"\"never lost...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>00137446b1aec28c</td>\n",
       "      <td>== September 20th Truce == \\n\\n According to s...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0013a435effa29bd</td>\n",
       "      <td>I'd never think I'd need to say it, but Wikipe...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0013be435187e84f</td>\n",
       "      <td>But this is not the article about government p...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0013fed3aeae76b7</td>\n",
       "      <td>DJ Robinson is gay as hell! he sucks his dick ...</td>\n",
       "      <td>Toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>001411adf8f1dd82</td>\n",
       "      <td>== Dracula's Grandmother == \\n\\n  \\n Dracula's...</td>\n",
       "      <td>Non_toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "0   00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1   0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...   \n",
       "2   00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...   \n",
       "3   00017563c3f7919a  :If you have a look back at the source, the in...   \n",
       "4   00017695ad8997eb          I don't anonymously edit articles at all.   \n",
       "5   0001ea8717f6de06  Thank you for understanding. I think very high...   \n",
       "6   00024115d4cbde0f  Please do not add nonsense to Wikipedia. Such ...   \n",
       "7   000247e83dcc1211                   :Dear god this site is horrible.   \n",
       "8   00025358d4737918  \" \\n Only a fool can believe in such numbers. ...   \n",
       "9   00026d1092fe71cc  == Double Redirects == \\n\\n When fixing double...   \n",
       "10  0002eadc3b301559  I think its crap that the link to roggenbier i...   \n",
       "11  0002f87b16116a7f  \"::: Somebody will invariably try to add Relig...   \n",
       "12  0003806b11932181  , 25 February 2010 (UTC) \\n\\n :::Looking it ov...   \n",
       "13  0003e1cccfd5a40a  \" \\n\\n It says it right there that it IS a typ...   \n",
       "14  00059ace3e3e9a53  \" \\n\\n == Before adding a new product to the l...   \n",
       "15  000634272d0d44eb  ==Current Position== \\n Anyone have confirmati...   \n",
       "16  000663aff0fffc80                           this other one from 1897   \n",
       "17  000689dd34e20979  == Reason for banning throwing == \\n\\n This ar...   \n",
       "18  000834769115370c  :: Wallamoose was changing the cited material ...   \n",
       "19  000844b52dee5f3f             |blocked]] from editing Wikipedia.   |   \n",
       "20  00084da5d4ead7aa  ==Indefinitely blocked== \\n I have indefinitel...   \n",
       "21  00091c35fa9d0465  == Arabs are committing genocide in Iraq, but ...   \n",
       "22  000968ce11f5ee34  Please stop. If you continue to vandalize Wiki...   \n",
       "23  0009734200a85047  == Energy  == \\n\\n I have edited the introduct...   \n",
       "24  00097b6214686db5  :yeah, thanks for reviving the tradition of pi...   \n",
       "25  0009aef4bd9e1697  MLM Software,NBFC software,Non Banking Financi...   \n",
       "26  000a02d807ae0254  @RedSlash, cut it short. If you have sources s...   \n",
       "27  000a6c6d4e89b9bc  ==================== \\n Deception is the way o...   \n",
       "28  000bafe2080bba82  . \\n\\n           Jews are not a race because y...   \n",
       "29  000bf0a9894b2807  :::If Ollie or others think that one list of t...   \n",
       "30  000c50dceb1eed2b  \" \\n *Support Per Jimbo and WP:google \"\"Climat...   \n",
       "31  000c9b92318552d1               Professors to the Manhatten Project.   \n",
       "32  000ce41d86f2b886  :::::I have added more wikilinks to my section...   \n",
       "33  000cf60dbaed8c02  \" \\n\\n :Not sure whether this is notable enoug...   \n",
       "34  000d4f120d5a7303                       일이삼사오육칠팔구하고십이요 에헤헤 으헤 으헤 으허허   \n",
       "35  000d60becb7d1a67  I've deleted the page , as we have no evidence...   \n",
       "36  000fc381d4895598  == Nation Radio - request for comment == \\n\\n ...   \n",
       "37  000ff37cf57ab537                          \"\"\" (per your user page)\"   \n",
       "38  001068b809feee6b  \" \\n\\n ==balance== \\n This page has one senten...   \n",
       "39  0011c58fcfd6bf91  \" \\n\\n *@EdJohnston. Your question was about f...   \n",
       "40  0011cefc680993ba                      REDIRECT Talk:Mi Vida Eres Tú   \n",
       "41  0011ef6aa33d42e6  \" \\n I'm not convinced that he was blind. Wher...   \n",
       "42  0012706ac77a7b37  == Thanks for the Barnstar! == \\n\\n Thank you ...   \n",
       "43  0012bb72f20ae971  \" \\n\\n == Ref: SS Ponzi Scheme == \\n\\n Hi Padi...   \n",
       "44  0012bbcbd6958302  \" \\n\\n Look, Gerry Spence has NOT \"\"never lost...   \n",
       "45  00137446b1aec28c  == September 20th Truce == \\n\\n According to s...   \n",
       "46  0013a435effa29bd  I'd never think I'd need to say it, but Wikipe...   \n",
       "47  0013be435187e84f  But this is not the article about government p...   \n",
       "48  0013fed3aeae76b7  DJ Robinson is gay as hell! he sucks his dick ...   \n",
       "49  001411adf8f1dd82  == Dracula's Grandmother == \\n\\n  \\n Dracula's...   \n",
       "\n",
       "        toxic  \n",
       "0       Toxic  \n",
       "1   Non_toxic  \n",
       "2   Non_toxic  \n",
       "3   Non_toxic  \n",
       "4   Non_toxic  \n",
       "5   Non_toxic  \n",
       "6   Non_toxic  \n",
       "7       Toxic  \n",
       "8   Non_toxic  \n",
       "9   Non_toxic  \n",
       "10      Toxic  \n",
       "11  Non_toxic  \n",
       "12  Non_toxic  \n",
       "13  Non_toxic  \n",
       "14  Non_toxic  \n",
       "15  Non_toxic  \n",
       "16  Non_toxic  \n",
       "17  Non_toxic  \n",
       "18  Non_toxic  \n",
       "19  Non_toxic  \n",
       "20  Non_toxic  \n",
       "21  Non_toxic  \n",
       "22  Non_toxic  \n",
       "23  Non_toxic  \n",
       "24      Toxic  \n",
       "25  Non_toxic  \n",
       "26  Non_toxic  \n",
       "27  Non_toxic  \n",
       "28  Non_toxic  \n",
       "29  Non_toxic  \n",
       "30  Non_toxic  \n",
       "31  Non_toxic  \n",
       "32  Non_toxic  \n",
       "33  Non_toxic  \n",
       "34  Non_toxic  \n",
       "35  Non_toxic  \n",
       "36  Non_toxic  \n",
       "37  Non_toxic  \n",
       "38  Non_toxic  \n",
       "39  Non_toxic  \n",
       "40  Non_toxic  \n",
       "41  Non_toxic  \n",
       "42  Non_toxic  \n",
       "43  Non_toxic  \n",
       "44  Non_toxic  \n",
       "45  Non_toxic  \n",
       "46  Non_toxic  \n",
       "47  Non_toxic  \n",
       "48      Toxic  \n",
       "49  Non_toxic  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
